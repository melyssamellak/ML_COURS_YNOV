{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-17 18:39:11,830] A new study created in memory with name: no-name-6e45a0a9-7f8e-417c-8bba-dfc0940b647a\n",
      "[I 2025-03-17 18:41:36,560] Trial 0 finished with value: 7.422996880662696 and parameters: {'n_estimators': 350, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 8, 'max_features': None}. Best is trial 0 with value: 7.422996880662696.\n",
      "[I 2025-03-17 18:41:46,323] Trial 1 finished with value: 17.652378344333144 and parameters: {'n_estimators': 300, 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 10, 'max_features': 'sqrt'}. Best is trial 0 with value: 7.422996880662696.\n",
      "[I 2025-03-17 18:43:03,361] Trial 2 finished with value: 9.429762614417559 and parameters: {'n_estimators': 400, 'max_depth': 30, 'min_samples_split': 3, 'min_samples_leaf': 6, 'max_features': 'sqrt'}. Best is trial 0 with value: 7.422996880662696.\n",
      "[I 2025-03-17 18:44:12,557] Trial 3 finished with value: 10.985803789690799 and parameters: {'n_estimators': 250, 'max_depth': 20, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 0 with value: 7.422996880662696.\n",
      "[I 2025-03-17 18:44:56,684] Trial 4 finished with value: 10.851995349959202 and parameters: {'n_estimators': 450, 'max_depth': 15, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'sqrt'}. Best is trial 0 with value: 7.422996880662696.\n",
      "[I 2025-03-17 18:45:29,466] Trial 5 finished with value: 9.443236643433384 and parameters: {'n_estimators': 150, 'max_depth': 30, 'min_samples_split': 4, 'min_samples_leaf': 6, 'max_features': 'sqrt'}. Best is trial 0 with value: 7.422996880662696.\n",
      "[I 2025-03-17 18:46:27,852] Trial 6 finished with value: 11.700713940410616 and parameters: {'n_estimators': 500, 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 7, 'max_features': 'log2'}. Best is trial 0 with value: 7.422996880662696.\n",
      "[I 2025-03-17 18:47:47,798] Trial 7 finished with value: 7.426760123484951 and parameters: {'n_estimators': 200, 'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 8, 'max_features': None}. Best is trial 0 with value: 7.422996880662696.\n",
      "[I 2025-03-17 18:47:54,400] Trial 8 finished with value: 17.516411754121492 and parameters: {'n_estimators': 200, 'max_depth': 5, 'min_samples_split': 7, 'min_samples_leaf': 1, 'max_features': 'sqrt'}. Best is trial 0 with value: 7.422996880662696.\n",
      "[I 2025-03-17 18:48:17,196] Trial 9 finished with value: 12.726699200553348 and parameters: {'n_estimators': 450, 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 0 with value: 7.422996880662696.\n",
      "[I 2025-03-17 18:53:17,770] Trial 10 finished with value: 2.797273420178856 and parameters: {'n_estimators': 350, 'max_depth': 20, 'min_samples_split': 6, 'min_samples_leaf': 10, 'max_features': None}. Best is trial 10 with value: 2.797273420178856.\n",
      "[I 2025-03-17 18:58:51,960] Trial 11 finished with value: 2.797273420178856 and parameters: {'n_estimators': 350, 'max_depth': 20, 'min_samples_split': 6, 'min_samples_leaf': 10, 'max_features': None}. Best is trial 10 with value: 2.797273420178856.\n",
      "[I 2025-03-17 19:04:27,338] Trial 12 finished with value: 2.797273420178856 and parameters: {'n_estimators': 350, 'max_depth': 20, 'min_samples_split': 7, 'min_samples_leaf': 10, 'max_features': None}. Best is trial 10 with value: 2.797273420178856.\n",
      "[I 2025-03-17 19:09:07,414] Trial 13 finished with value: 2.3247117947120937 and parameters: {'n_estimators': 300, 'max_depth': 25, 'min_samples_split': 6, 'min_samples_leaf': 10, 'max_features': None}. Best is trial 13 with value: 2.3247117947120937.\n",
      "[I 2025-03-17 19:14:25,419] Trial 14 finished with value: 1.8495252602336028 and parameters: {'n_estimators': 300, 'max_depth': 25, 'min_samples_split': 6, 'min_samples_leaf': 4, 'max_features': None}. Best is trial 14 with value: 1.8495252602336028.\n",
      "[I 2025-03-17 19:15:54,166] Trial 15 finished with value: 1.8685095785595378 and parameters: {'n_estimators': 100, 'max_depth': 25, 'min_samples_split': 8, 'min_samples_leaf': 4, 'max_features': None}. Best is trial 14 with value: 1.8495252602336028.\n",
      "[I 2025-03-17 19:17:29,042] Trial 16 finished with value: 1.8685095785595378 and parameters: {'n_estimators': 100, 'max_depth': 25, 'min_samples_split': 8, 'min_samples_leaf': 4, 'max_features': None}. Best is trial 14 with value: 1.8495252602336028.\n",
      "[I 2025-03-17 19:18:58,818] Trial 17 finished with value: 1.8534818192092621 and parameters: {'n_estimators': 100, 'max_depth': 25, 'min_samples_split': 9, 'min_samples_leaf': 3, 'max_features': None}. Best is trial 14 with value: 1.8495252602336028.\n",
      "[I 2025-03-17 19:19:15,864] Trial 18 finished with value: 11.132293895880391 and parameters: {'n_estimators': 200, 'max_depth': 25, 'min_samples_split': 10, 'min_samples_leaf': 3, 'max_features': 'log2'}. Best is trial 14 with value: 1.8495252602336028.\n",
      "[I 2025-03-17 19:20:39,556] Trial 19 finished with value: 4.458288792711193 and parameters: {'n_estimators': 150, 'max_depth': 15, 'min_samples_split': 9, 'min_samples_leaf': 3, 'max_features': None}. Best is trial 14 with value: 1.8495252602336028.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Meilleurs hyperparam√®tres trouv√©s par Optuna: {'n_estimators': 300, 'max_depth': 25, 'min_samples_split': 6, 'min_samples_leaf': 4, 'max_features': None}\n",
      "\n",
      "üîÑ Entra√Ænement du mod√®le final avec les meilleurs hyperparam√®tres...\n",
      "‚úÖ Mod√®le final entra√Æn√© avec succ√®s !\n",
      "\n",
      "üìä **√âvaluation du mod√®le final:**\n",
      "MAE (Erreur absolue moyenne) : 1.85 min\n",
      "MSE (Erreur quadratique moyenne) : 19.34\n",
      "RMSE (Racine de l'erreur quadratique moyenne) : 4.40 min\n",
      "R¬≤ Score : 0.9937\n",
      "\n",
      "‚úÖ Mod√®le sauvegard√© sous 'best_flight_delay_model2.pkl'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import optuna\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# ==========================\n",
    "# 1Ô∏è‚É£  CHARGEMENT & NETTOYAGE\n",
    "# ==========================\n",
    "df = pd.read_csv('../projet_final/flights_sample_3m.csv')\n",
    "\n",
    "# Filtrer un seul a√©roport\n",
    "airport = 'JFK'\n",
    "df = df[df['ORIGIN'] == airport]\n",
    "\n",
    "# Supprimer les vols annul√©s\n",
    "df = df[df['CANCELLED'] == 0]\n",
    "df.drop(columns=['CANCELLED', 'CANCELLATION_CODE'], inplace=True)\n",
    "\n",
    "# Colonnes temporelles au format hhmm\n",
    "time_hhmm_cols = ['WHEELS_ON','WHEELS_OFF', 'ARR_TIME', 'CRS_ARR_TIME','CRS_DEP_TIME','DEP_TIME']\n",
    "\n",
    "# Colonnes temporelles en minutes\n",
    "time_cols = ['TAXI_IN', 'AIR_TIME', 'ELAPSED_TIME', 'ARR_DELAY',\n",
    "             'DELAY_DUE_CARRIER', 'DELAY_DUE_WEATHER', 'DELAY_DUE_NAS',\n",
    "             'DELAY_DUE_SECURITY', 'DELAY_DUE_LATE_AIRCRAFT']\n",
    "\n",
    "# Conversion des colonnes hhmm en entiers (si elles sont lues comme float)\n",
    "for col in time_hhmm_cols:\n",
    "    df[col] = df[col].fillna(0).astype(int)\n",
    "\n",
    "# Fonction pour soustraire des minutes d'un format hhmm\n",
    "def subtract_minutes(hhmm, minutes):\n",
    "    if pd.isna(hhmm) or pd.isna(minutes):\n",
    "        return np.nan  # √âvite les erreurs si des valeurs sont NaN\n",
    "\n",
    "    hours = hhmm // 100\n",
    "    mins = hhmm % 100\n",
    "    total_mins = hours * 60 + mins - minutes\n",
    "    \n",
    "    if total_mins < 0:  # G√©rer les cas o√π l'heure passe √† la veille\n",
    "        total_mins += 24 * 60\n",
    "\n",
    "    new_hours = (total_mins // 60) % 24  # Pour √©viter des erreurs sur 24h\n",
    "    new_mins = total_mins % 60\n",
    "    return new_hours * 100 + new_mins  # Retourne en format hhmm\n",
    "\n",
    "# Remplacement des valeurs nulles pour ARR_TIME avec CRS_ARR_TIME\n",
    "df['ARR_TIME'] = df['ARR_TIME'].fillna(df['CRS_ARR_TIME'])\n",
    "\n",
    "# Remplacement des valeurs nulles pour WHEELS_ON\n",
    "df['WHEELS_ON'] = df.apply(lambda row: subtract_minutes(row['CRS_ARR_TIME'], row['TAXI_IN']) \n",
    "                           if pd.notna(row['TAXI_IN']) and pd.isna(row['WHEELS_ON']) \n",
    "                           else row['WHEELS_ON'], axis=1)\n",
    "\n",
    "# Remplacement des valeurs nulles restantes pour WHEELS_ON et ARR_TIME avec la m√©diane\n",
    "for col in time_hhmm_cols:\n",
    "    df[col] = df[col].fillna(df[col].median()).astype(int)\n",
    "\n",
    "# Remplacement des valeurs manquantes pour les dur√©es en minutes\n",
    "df[time_cols] = df[time_cols].fillna(df[time_cols].median())\n",
    "\n",
    "# Convertir la date\n",
    "df['FL_DATE'] = pd.to_datetime(df['FL_DATE'])\n",
    "\n",
    "# Extraire des nouvelles features temporelles\n",
    "df['YEAR'] = df['FL_DATE'].dt.year\n",
    "df['MONTH'] = df['FL_DATE'].dt.month\n",
    "df['DAY'] = df['FL_DATE'].dt.day\n",
    "df['DAY_OF_WEEK'] = df['FL_DATE'].dt.dayofweek\n",
    "df['HOUR'] = df['CRS_DEP_TIME'] // 100\n",
    "df['IS_WEEKEND'] = df['DAY_OF_WEEK'].apply(lambda x: 1 if x in [5, 6] else 0)\n",
    "df['SEASON'] = df['MONTH'].map({12: 'Winter', 1: 'Winter', 2: 'Winter',\n",
    "                                 3: 'Spring', 4: 'Spring', 5: 'Spring',\n",
    "                                 6: 'Summer', 7: 'Summer', 8: 'Summer',\n",
    "                                 9: 'Autumn', 10: 'Autumn', 11: 'Autumn'})\n",
    "\n",
    "# ==========================\n",
    "# 2Ô∏è‚É£  SELECTION DES FEATURES\n",
    "# ==========================\n",
    "features = ['AIRLINE_CODE', 'DEST', 'CRS_DEP_TIME','DEP_TIME','DEP_DELAY', 'YEAR', 'MONTH', \n",
    "            'DAY', 'DAY_OF_WEEK', 'HOUR', 'IS_WEEKEND', 'SEASON', 'DELAY_DUE_CARRIER', \n",
    "            'DELAY_DUE_WEATHER', 'DELAY_DUE_NAS', 'DELAY_DUE_SECURITY', \n",
    "            'DELAY_DUE_LATE_AIRCRAFT', 'WHEELS_OFF', 'WHEELS_ON', 'ELAPSED_TIME', 'CRS_ELAPSED_TIME']\n",
    "target = 'ARR_DELAY'\n",
    "\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "# S√©parer en train/val\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# ==========================\n",
    "# 3Ô∏è‚É£  PIPELINE DE TRANSFORMATION\n",
    "# ==========================\n",
    "num_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "cat_features = X.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', StandardScaler(), num_features),\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore'), cat_features)\n",
    "])\n",
    "\n",
    "# ==========================\n",
    "# 4Ô∏è‚É£  OPTIMISATION DES HYPERPARAM√àTRES (GRIDSEARCH + OPTUNA)\n",
    "# ==========================\n",
    "def objective(trial):\n",
    "    n_estimators = trial.suggest_int('n_estimators', 100, 500, step=50)\n",
    "    max_depth = trial.suggest_int('max_depth', 5, 30, step=5)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 10)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 10)\n",
    "    max_features = trial.suggest_categorical('max_features', ['sqrt', 'log2', None])\n",
    "\n",
    "    model = RandomForestRegressor(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        max_features=max_features,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', model)\n",
    "    ])\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_val)\n",
    "    \n",
    "    return mean_absolute_error(y_val, y_pred)\n",
    "\n",
    "# Lancer Optuna pour trouver les meilleurs param√®tres\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=20)  # Augmente le nombre d'essais si n√©cessaire\n",
    "\n",
    "best_params = study.best_params\n",
    "print(\"\\nMeilleurs hyperparam√®tres trouv√©s par Optuna:\", best_params)\n",
    "\n",
    "# ==========================\n",
    "# 5Ô∏è‚É£  ENTRA√éNEMENT FINAL\n",
    "# ==========================\n",
    "best_model = RandomForestRegressor(\n",
    "    **best_params,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', best_model)\n",
    "])\n",
    "\n",
    "print(\"\\nüîÑ Entra√Ænement du mod√®le final avec les meilleurs hyperparam√®tres...\")\n",
    "pipeline.fit(X_train, y_train)\n",
    "print(\"‚úÖ Mod√®le final entra√Æn√© avec succ√®s !\")\n",
    "\n",
    "# ==========================\n",
    "# 6Ô∏è‚É£  √âVALUATION DU MOD√àLE\n",
    "# ==========================\n",
    "y_pred = pipeline.predict(X_val)\n",
    "\n",
    "mae = mean_absolute_error(y_val, y_pred)\n",
    "mse = mean_squared_error(y_val, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_val, y_pred)\n",
    "\n",
    "print(f\"\\nüìä **√âvaluation du mod√®le final:**\")\n",
    "print(f\"MAE (Erreur absolue moyenne) : {mae:.2f} min\")\n",
    "print(f\"MSE (Erreur quadratique moyenne) : {mse:.2f}\")\n",
    "print(f\"RMSE (Racine de l'erreur quadratique moyenne) : {rmse:.2f} min\")\n",
    "print(f\"R¬≤ Score : {r2:.4f}\")\n",
    "\n",
    "# ==========================\n",
    "# 7Ô∏è‚É£  SAUVEGARDE DU MOD√àLE\n",
    "# ==========================\n",
    "joblib.dump(pipeline, \"best_flight_delay_model2.pkl\")\n",
    "print(\"\\n‚úÖ Mod√®le sauvegard√© sous 'best_flight_delay_model2.pkl'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
